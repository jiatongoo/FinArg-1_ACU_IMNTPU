{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g4ruPch_RLMa"
   },
   "source": [
    "# Setup OpenAI Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GgUK7wprQCU1"
   },
   "outputs": [],
   "source": [
    "!pip install -q openai tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jx6zmb1GP9eH",
    "outputId": "c94d5d02-6859-485f-94fc-f9c17a4aed9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the OpenAI API Key: ··········\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "import tiktoken\n",
    "import getpass\n",
    "\n",
    "api_key = getpass.getpass(\"Enter the OpenAI API Key: \")\n",
    "assert api_key.startswith(\"sk-\"), 'OpenAI API Keys begin with \"sk-\".'\n",
    "openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N1e30IlEuS6N"
   },
   "outputs": [],
   "source": [
    "enc = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "\n",
    "emotions = [\n",
    "    \"claim\",\n",
    "    \"premise\",\n",
    "]\n",
    "\n",
    "def create_logit_biases(emotions, bias_weight):\n",
    "    \"\"\"Creates a dict of tokens for ChatGPT to use mostly exclusively.\"\"\"\n",
    "    bias_dict = {}\n",
    "    for emotion in emotions:\n",
    "        token_ids = enc.encode(emotion)\n",
    "        for token_id in token_ids:\n",
    "            bias_dict[token_id] = bias_weight\n",
    "    return bias_dict\n",
    "\n",
    "def chatgpt_sentiment(prompt, emotions=None):\n",
    "    if not emotions:\n",
    "        emotions = globals().get(\"emotions\")\n",
    "    emotion_list_str = [f\"- {x}\\n\" for x in emotions]\n",
    "    eos_str = \".\"\n",
    "    #emotionally\n",
    "    system = f\"You are a logician. Classify the sentiment of the user's text with ONLY ONE OF THE FOLLOWING CLASSIFICATION:\\n{''.join(emotion_list_str)}\\n\\nAfter classifying a text, respond with \\\"{eos_str}\\\".\"\n",
    "    r = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        stop=eos_str,\n",
    "        max_tokens=20,  # safeguard from going infinite\n",
    "        temperature=0.0,  # deterministic, will use largest logit\n",
    "        logit_bias=create_logit_biases(\n",
    "            emotions + [eos_str], 15  # may want to tweak bias weight\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    result = r[\"choices\"][0][\"message\"][\"content\"]\n",
    "    if result == \"\":  # if ChatGPT decides to not return an emotion\n",
    "        result = \"N/A\"\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bPsrwd_ERo1V"
   },
   "source": [
    "# Generate The Sentiment\n",
    "Test Cases: \n",
    "Class 0: Premise.\n",
    "Class 1: Claim.\n",
    "Input the text you want to classify in the cell below, then run the cell!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "aAa5mKsxSmBm",
    "outputId": "8d1c8ae8-bf9b-4cf0-d754-21f42324e894"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'premise'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"And in that context, of course, they're lifting and shifting some of the older workloads, but they're modernizing the entire business process flow.\" #@param {type:\"string\"}\n",
    "chatgpt_sentiment(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "WYdc8HjpP9eK",
    "outputId": "409d1865-547b-4ea3-de7e-65e7265b01a9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'claim'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatgpt_sentiment(\"It's a number that is incredibly competitive in our industry, and we want to continue to keep it that way.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "K1wJoRRVP9eK",
    "outputId": "8b46a54f-6979-4e37-b2c7-30babee3b67f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'claim'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatgpt_sentiment(\"Even while in International, we're continuing to invest in a lot of areas, we continue to frontload Prime benefits for the newer geographies, we continue to launch new countries as we launch Prime in Australia recently.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "esITZWeoP9eL",
    "outputId": "5a050c37-f354-4eb0-c3c0-3b4a136f29bd"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'claim'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatgpt_sentiment(\"See, first of all, I'd say the opportunity for our shareholders when they think about Microsoft has never been better.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "yvUb5q04P9eM",
    "outputId": "4a6166fa-ca3f-4954-9065-dcabf9f72851"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'claim'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatgpt_sentiment(\"So this is an architectural design point that we have built from the ground up from day one and it's good to see people validating it now and elsewhere and we will take that as a validation of something that we thought of a long time ago.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nTfNx0hiyOGx"
   },
   "source": [
    "# Save json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uj2YMfvbD9wC",
    "outputId": "5cc4c4e4-abd0-44ef-e9a1-ff8f7e28a9b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import json\n",
    "\n",
    "with open('/content/drive/MyDrive/ECC_Argument_Classification_Test.json', 'r', encoding='utf-8') as f:\n",
    "    original_data = json.load(f)\n",
    "\n",
    "sentences = [item['sentence'] for item in original_data]\n",
    "\n",
    "results = []\n",
    "for sentence in sentences[:60]:\n",
    "    result = chatgpt_sentiment(sentence)\n",
    "    if result == \"claim\":\n",
    "        sentiment = 1\n",
    "    elif result == \"premise\":\n",
    "        sentiment = 0\n",
    "    else:\n",
    "        sentiment = -1\n",
    "    results.append(sentiment)\n",
    "\n",
    "output_data = []\n",
    "for item, sentiment in zip(original_data, results):\n",
    "    item['Prediction'] = sentiment\n",
    "    output_data.append(item)\n",
    "\n",
    "with open('/content/drive/MyDrive/ECC_Argument_Classification_Test60.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(output_data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GANlfN2i2xj0"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load JSON file\n",
    "with open('/content/drive/MyDrive/ECC_Argument_Classification_Test.json', 'r', encoding='utf-8') as f:\n",
    "    original_data = json.load(f)\n",
    "\n",
    "# Extract sentences\n",
    "sentences = [item['sentence'] for item in original_data[900:970]]\n",
    "\n",
    "results = []\n",
    "for sentence in sentences:\n",
    "    result = chatgpt_sentiment(sentence)\n",
    "    if result == \"claim\":\n",
    "        sentiment = 1\n",
    "    elif result == \"premise\":\n",
    "        sentiment = 0\n",
    "    else:\n",
    "        sentiment = -1  # If sentiment is unrecognizable, then -1\n",
    "    results.append(sentiment)\n",
    "\n",
    "# Create a list of dictionaries containing sentences and sentiment results, and retain the original JSON structure\n",
    "output_data = []\n",
    "for item, sentiment in zip(original_data[900:970], results):\n",
    "    item['Prediction'] = sentiment\n",
    "    output_data.append(item)\n",
    "\n",
    "# Append the results to the existing JSON file\n",
    "with open('/content/drive/MyDrive/ECC_Argument_Classification_Test970.json', 'a', encoding='utf-8') as f:\n",
    "    for item in output_data:\n",
    "        json.dump(item, f, ensure_ascii=False)\n",
    "        f.write(',\\n')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
